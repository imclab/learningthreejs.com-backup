<!doctype html>
<html>
	<head>
		<title>learningthree.js boiler plate for three.js</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		
			
		<script src="vendor/three.js/Three.js"></script>
		<script src="vendor/three.js/Detector.js"></script>
		<!-- https://github.com/mrdoob/stats.js -->
		<script src="vendor/three.js/Stats.js"></script>

		<script src="vendor/threex/THREEx.screenshot.js"></script>
		<script src="vendor/threex/THREEx.FullScreen.js"></script>
		<script src="vendor/threex/THREEx.WindowResize.js"></script>
		<script src="vendor/threex.dragpancontrols.js"></script>

		<link  href="css/main.css" rel="stylesheet"/>
	</head>
<body>
	<!-- three.js container -->
    	<div id="container"></div>
	<!-- info on screen display -->
	<div id="info">
		<div class="top">
			<a href="http://learningthreejs.com/blog/2011/12/20/boilerplate-for-three-js/" target="_blank">LearningThree.js</a>
			boiler plate for
			<a href="https://github.com/mrdoob/three.js/" target="_blank">three.js</a>
		</div>
		<div class="bottom" id="inlineDoc" >
			- <i>p</i> for screenshot
		</div> 
	</div> 
	<video id="video" loop style="display:none">
		<source src="videos/sintel.mp4" type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'>
		<source src="videos/sintel.ogv" type='video/ogg; codecs="theora, vorbis"'>
	</video>

	<script type="text/javascript">
		var stats, scene, renderer;
		var camera, tvset;

		var cameraRTT, sceneRTT;

		if( !init() )	animate();

		// init the scene
		function init(){

			if( Detector.webgl ){
				renderer = new THREE.WebGLRenderer({
					antialias		: true,	// to get smoother output
					preserveDrawingBuffer	: true	// to allow screenshot
				});
				renderer.autoClear = false
			}else{
				renderer	= new THREE.CanvasRenderer();
			}
			renderer.setSize( window.innerWidth, window.innerHeight );
			document.getElementById('container').appendChild(renderer.domElement);

			// add Stats.js - https://github.com/mrdoob/stats.js
			stats = new Stats();
			stats.domElement.style.position	= 'absolute';
			stats.domElement.style.bottom	= '0px';
			document.body.appendChild( stats.domElement );

			// setup RTT stuff
			var rttW	= 256;
			var rttH	= 256;
			sceneRTT	= new THREE.Scene();
			cameraRTT	= new THREE.OrthographicCamera( rttW / - 2, rttW / 2, rttH / 2, rttH / - 2, -10000, 10000 );
			cameraRTT.position.z = 100;

			rtTexture	= new THREE.WebGLRenderTarget( rttW, rttH, {
				minFilter	: THREE.LinearFilter,
				magFilter	: THREE.NearestFilter,
				format		: THREE.RGBFormat
			});
			
			var plane	= new THREE.PlaneGeometry( rttW, rttH );
			quad		= new THREE.Mesh( plane, new THREE.MeshNormalMaterial() );
			quad.position.z = -100;
			sceneRTT.add( quad );
			
			var geometry	= new THREE.TorusGeometry( 80, 25, 15, 30 );
			var material	= new THREE.MeshNormalMaterial();
			var mesh	= new THREE.Mesh( geometry, material );
			iTorus	= mesh;
			mesh.position.set( 0, 0, 100 );
			mesh.scale.set( 1.5, 1.5, 1.5 );
			sceneRTT.add( mesh );


			// create a scene
			scene = new THREE.Scene();

			// put a camera in the scene
			camera	= new THREE.PerspectiveCamera(35, window.innerWidth / window.innerHeight, 1, 10000 );
			camera.position.set(0, 1, 10);
			scene.add(camera);

			// create a camera contol
			cameraControls	= new THREEx.DragPanControls(camera)

			// transparently support window resize
			THREEx.WindowResize.bind(renderer, camera);
			// allow 'p' to make screenshot
			THREEx.Screenshot.bindKey(renderer);
			// allow 'f' to go fullscreen where this feature is supported
			if( THREEx.FullScreen.available() ){
				THREEx.FullScreen.bindKey();		
				document.getElementById('inlineDoc').innerHTML	+= "- <i>f</i> for fullscreen";
			}

			// here you add your objects
			// - you will most likely replace this part by your own

			var light	= new THREE.AmbientLight( 0x444444 );
			scene.add( light );			

			var light	= new THREE.DirectionalLight( 0xff8000, 1.5 );
			light.position.set( 1, 0, 1 ).normalize();
			scene.add( light );
			
			var light	= new THREE.DirectionalLight( 0xff8000, 1.5 );
			light.position.set( -1, 1, 0 ).normalize();
			scene.add( light );

			video	= document.getElementById( 'video' );

	video	= document.createElement('video');
	video.width	= 320;
	video.height	= 240;
	video.volume	= 0;
	video.autoplay	= true;
	
	navigator.webkitGetUserMedia('video',
		function(stream){
			var url		= webkitURL.createObjectURL(stream);
			video.src	= url;
		},
		function(error){
			alert('you got no WebRTC webcam');
		}
	);

			videoTexture	= new THREE.Texture( video );
			videoTexture.minFilter	= THREE.LinearFilter;
			videoTexture.magFilter	= THREE.LinearFilter;
			videoTexture.format	= THREE.RGBFormat;

			var geometry	= new THREE.CubeGeometry( 1, 1, 1 );
			//var geometry	= new THREE.SphereGeometry( 1 );
			var material	= new THREE.MeshLambertMaterial({
				ambient	: 0x444444,
				color	: 0xffffff,
				//map	: rtTexture
				map	: videoTexture
			});
			var mesh	= new THREE.Mesh( geometry, material );
			mesh.scale.multiplyScalar(2);
			mesh.position.y	= 0.5;
			mesh.position.z	= 4;
			scene.add( mesh );
			iCube	= mesh;

			var geometry	= new THREE.PlaneGeometry( 1, 1, 1 );
			var mesh	= new THREE.Mesh( geometry, material );
			mesh.scale.multiplyScalar(2);
			mesh.position.x	= 2.5;
			mesh.position.z	= 4;
			scene.add( mesh );



			var geometry	= new THREE.TorusGeometry( 1, 0.42, 16, 16 );
			var geometry	= new THREE.SphereGeometry( 1, 32, 16 );
			//var material	= new THREE.MeshNormalMaterial();
			var mesh	= new THREE.Mesh( geometry, material );
			mesh.rotation.y	= -Math.PI/2;
			//scene.add( mesh );


			var url	= 'models/iras tv/models/iras tv.dae';
			//var url	= 'models/viper/models/Viper Mk VII.dae';
			var url	= 'models/Old Television Set 01/models/Old Television Set 01.dae';

			tvset	= new THREE.Object3D();
			tvset.position.x	= -2.8;
			tvset.position.y	= -0.5;
			tvset.position.z	= 5;
			tvset.rotation.y	= Math.PI/3;
			tvset.scale.multiplyScalar(0.9);
			scene.add(tvset);
			
			new THREE.ColladaLoader().load(url, function(collada){
			console.log("adding collada object")
				var object3d		= collada.scene;
				object3d.scale.multiplyScalar(1/200);
				object3d.position.y	= -2;
				//object3d.position.z	= 100;

				object3d.rotation.x	= -Math.PI/2;
				//object3d.rotation.y	= -Math.PI;
				//object3d.rotation.z	=  Math.PI/2;
				tvset.add(object3d);

				var geometry	= new THREE.PlaneGeometry( 1, 1 );
				var material	= new THREE.MeshBasicMaterial({
					color	: 0xffffff,
					//map	: rtTexture
					map	: videoTexture
				});
				var mesh	= new THREE.Mesh( geometry, material );
				mesh.scale.set(1.9, 1.6, 1);
				mesh.position.y	= 1.45;
				mesh.position.z	= 0.8;
				tvset.add( mesh );

			});

		}

		// animation loop
		function animate() {

			// loop on request animation loop
			// - it has to be at the begining of the function
			// - see details at http://my.opera.com/emoller/blog/2011/12/20/requestanimationframe-for-smart-er-animating
			requestAnimationFrame( animate );

			// do the render
			render();

			// update stats
			stats.update();
		}

		// render the scene
		function render() {
			// update camera controls
			cameraControls.update();
			
			//if( tvset )	tvset.rotation.y	+= 0.01;
			
			iTorus.rotation.x	+= 0.01;
			iTorus.rotation.y	+= 0.01;

			iCube.rotation.x	+= 0.01;
			iCube.rotation.y	+= 0.01;

			if( video.readyState === video.HAVE_ENOUGH_DATA ){
				if ( videoTexture )	videoTexture.needsUpdate = true;
			}

			renderer.clear();
			
			// Render first scene into texture
			
			renderer.render( sceneRTT, cameraRTT, rtTexture, true );
			
			// Render second scene to screen
			// (using first scene as regular texture)

			// actually render the scene
			renderer.render(scene, camera);
		}
	</script>
</body>
</html>
